{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5_y4j87FBv_s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "import json\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import requests\n",
        "    HUGGINGFACE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    HUGGINGFACE_AVAILABLE = False"
      ],
      "metadata": {
        "id": "wRsqYl-fBwn6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class StoryState:\n",
        "    \"\"\"Represents a state in story planning\"\"\"\n",
        "    characters: Dict[str, Dict[str, Any]]\n",
        "    location: str\n",
        "    plot_points: List[str]\n",
        "    tension_level: float\n",
        "\n",
        "    def to_string(self) -> str:\n",
        "        \"\"\"Convert state to string for LLM\"\"\"\n",
        "        desc = f\"Location: {self.location}\\n\"\n",
        "        desc += \"Characters:\\n\"\n",
        "        for char, attrs in self.characters.items():\n",
        "            desc += f\"  {char}: \"\n",
        "            desc += \", \".join([f\"{k}={v}\" for k, v in attrs.items()])\n",
        "            desc += \"\\n\"\n",
        "        desc += f\"Plot points completed: {', '.join(self.plot_points) if self.plot_points else 'None'}\\n\"\n",
        "        desc += f\"Tension level: {self.tension_level:.1f}\"\n",
        "        return desc\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"Deep copy of state\"\"\"\n",
        "        return StoryState(\n",
        "            characters={k: v.copy() for k, v in self.characters.items()},\n",
        "            location=self.location,\n",
        "            plot_points=self.plot_points.copy(),\n",
        "            tension_level=self.tension_level\n",
        "        )\n",
        "\n",
        "@dataclass\n",
        "class StoryAction:\n",
        "    \"\"\"Represents an action in story\"\"\"\n",
        "    action_type: str  # \"dialogue\", \"move\", \"conflict\", \"reveal\"\n",
        "    actor: str\n",
        "    target: Optional[str] = None\n",
        "    content: str = \"\"\n",
        "\n",
        "    def to_string(self) -> str:\n",
        "        if self.target:\n",
        "            return f\"{self.actor} {self.action_type} with {self.target}: {self.content}\"\n",
        "        return f\"{self.actor} {self.action_type}: {self.content}\"\n",
        "\n",
        "@dataclass\n",
        "class StoryGoal:\n",
        "    \"\"\"Defines the target story state\"\"\"\n",
        "    required_plot_points: List[str]\n",
        "    target_relationships: Dict[str, str]\n",
        "    target_location: Optional[str] = None\n",
        "    min_tension_arc: bool = True"
      ],
      "metadata": {
        "id": "y9vtdbiHB2YA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActualLLMWorldModel:\n",
        "    \"\"\"World model using real LLM for story planning\"\"\"\n",
        "\n",
        "    def __init__(self, model_type=\"openai\", api_key=None, hf_token=None):\n",
        "        \"\"\"\n",
        "        Initialize LLM model\n",
        "        model_type: \"openai\", \"huggingface\", or \"hybrid\"\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.locations = [\"village\", \"castle\", \"forest\", \"home\", \"mountain\", \"river\"]\n",
        "\n",
        "        if model_type == \"openai\" and OPENAI_AVAILABLE:\n",
        "            # Use environment variable or provided key\n",
        "            api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
        "            if api_key:\n",
        "                self.client = OpenAI(api_key=api_key)\n",
        "                self.model_name = \"gpt-3.5-turbo\"\n",
        "            else:\n",
        "                print(\"Warning: No OpenAI API key provided. Falling back to hybrid mode.\")\n",
        "                self.model_type = \"hybrid\"\n",
        "\n",
        "        elif model_type == \"huggingface\":\n",
        "            self.hf_token = hf_token or os.getenv(\"HF_TOKEN\")\n",
        "            self.hf_model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "            self.api_url = f\"https://api-inference.huggingface.co/models/{self.hf_model}\"\n",
        "\n",
        "        else:\n",
        "            # Hybrid mode - use heuristics with simulated LLM behavior\n",
        "            self.model_type = \"hybrid\"\n",
        "            print(\"Using hybrid mode (heuristics + simulated LLM)\")\n",
        "\n",
        "    def get_valid_actions(self, state: StoryState, goal: StoryGoal) -> List[StoryAction]:\n",
        "        \"\"\"Generate valid actions using LLM\"\"\"\n",
        "\n",
        "        if self.model_type == \"openai\" and OPENAI_AVAILABLE:\n",
        "            return self._get_actions_openai(state, goal)\n",
        "        elif self.model_type == \"huggingface\":\n",
        "            return self._get_actions_huggingface(state, goal)\n",
        "        else:\n",
        "            return self._get_actions_hybrid(state, goal)\n",
        "\n",
        "    def _get_actions_openai(self, state: StoryState, goal: StoryGoal) -> List[StoryAction]:\n",
        "        \"\"\"Get actions from OpenAI API\"\"\"\n",
        "        prompt = f\"\"\"You are a story planner. Given the current state and goal, suggest 5-10 possible story actions.\n",
        "\n",
        "Current State:\n",
        "{state.to_string()}\n",
        "\n",
        "Goal:\n",
        "- Required plot points: {goal.required_plot_points}\n",
        "- Target relationships: {goal.target_relationships}\n",
        "- Target location: {goal.target_location}\n",
        "\n",
        "Generate actions in this exact format (one per line):\n",
        "[actor]|[action_type]|[target]|[content]\n",
        "\n",
        "Where action_type is one of: dialogue, move, conflict, reveal\n",
        "Example: Hero|dialogue|Mentor|asks for guidance\n",
        "\n",
        "Focus on actions that progress toward the goal.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.7,\n",
        "                max_tokens=300\n",
        "            )\n",
        "\n",
        "            return self._parse_actions(response.choices[0].message.content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"OpenAI API error: {e}\")\n",
        "            return self._get_actions_hybrid(state, goal)\n",
        "\n",
        "    def _get_actions_huggingface(self, state: StoryState, goal: StoryGoal) -> List[StoryAction]:\n",
        "        \"\"\"Get actions from HuggingFace Inference API\"\"\"\n",
        "        prompt = f\"\"\"Generate 5 story actions for:\n",
        "State: {state.to_string()}\n",
        "Goal: {goal.required_plot_points}\n",
        "Format: actor|action_type|target|content\"\"\"\n",
        "\n",
        "        headers = {\"Authorization\": f\"Bearer {self.hf_token}\"} if self.hf_token else {}\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.api_url,\n",
        "                headers=headers,\n",
        "                json={\"inputs\": prompt, \"parameters\": {\"max_new_tokens\": 200}}\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                text = response.json()[0][\"generated_text\"]\n",
        "                return self._parse_actions(text)\n",
        "            else:\n",
        "                return self._get_actions_hybrid(state, goal)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"HuggingFace API error: {e}\")\n",
        "            return self._get_actions_hybrid(state, goal)\n",
        "\n",
        "    def _get_actions_hybrid(self, state: StoryState, goal: StoryGoal) -> List[StoryAction]:\n",
        "        \"\"\"Hybrid approach: Generate actions using heuristics\"\"\"\n",
        "        actions = []\n",
        "        chars = list(state.characters.keys())\n",
        "\n",
        "        # Priority 1: Goal-achieving actions\n",
        "        if goal.target_location and state.location != goal.target_location:\n",
        "            for actor in chars[:2]:  # Limit for efficiency\n",
        "                actions.append(StoryAction(\n",
        "                    action_type=\"move\",\n",
        "                    actor=actor,\n",
        "                    content=f\"travels to {goal.target_location}\"\n",
        "                ))\n",
        "\n",
        "        # Priority 2: Plot point actions\n",
        "        for required in goal.required_plot_points:\n",
        "            if required not in state.plot_points:\n",
        "                if \"revelation\" in required:\n",
        "                    for actor in chars[:2]:\n",
        "                        actions.append(StoryAction(\n",
        "                            action_type=\"reveal\",\n",
        "                            actor=actor,\n",
        "                            content=\"makes important discovery\"\n",
        "                        ))\n",
        "                elif \"conflict\" in required:\n",
        "                    parts = required.split(\"_\")\n",
        "                    if len(parts) >= 3:\n",
        "                        actor, target = parts[1], parts[2]\n",
        "                        if actor in chars and target in chars:\n",
        "                            actions.append(StoryAction(\n",
        "                                action_type=\"conflict\",\n",
        "                                actor=actor,\n",
        "                                target=target,\n",
        "                                content=\"confronts\"\n",
        "                            ))\n",
        "\n",
        "        # Priority 3: Relationship actions\n",
        "        for char, target_rel in goal.target_relationships.items():\n",
        "            if char in state.characters:\n",
        "                for other in chars:\n",
        "                    if other != char:\n",
        "                        if target_rel == \"friendly\":\n",
        "                            actions.append(StoryAction(\n",
        "                                action_type=\"dialogue\",\n",
        "                                actor=char,\n",
        "                                target=other,\n",
        "                                content=\"asks for help\"\n",
        "                            ))\n",
        "                        elif target_rel == \"tense\":\n",
        "                            actions.append(StoryAction(\n",
        "                                action_type=\"dialogue\",\n",
        "                                actor=char,\n",
        "                                target=other,\n",
        "                                content=\"confronts\"\n",
        "                            ))\n",
        "\n",
        "        # Add some variety\n",
        "        if len(actions) < 5:\n",
        "            for actor in chars[:2]:\n",
        "                for target in chars[:2]:\n",
        "                    if target != actor and len(actions) < 10:\n",
        "                        actions.append(StoryAction(\n",
        "                            action_type=\"dialogue\",\n",
        "                            actor=actor,\n",
        "                            target=target,\n",
        "                            content=\"reveals secret\"\n",
        "                        ))\n",
        "\n",
        "        return actions[:10]\n",
        "\n",
        "    def _parse_actions(self, text: str) -> List[StoryAction]:\n",
        "        \"\"\"Parse LLM response into StoryAction objects\"\"\"\n",
        "        actions = []\n",
        "        lines = text.strip().split('\\n')\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if '|' in line:\n",
        "                parts = line.split('|')\n",
        "                if len(parts) >= 3:\n",
        "                    actor = parts[0].strip()\n",
        "                    action_type = parts[1].strip()\n",
        "                    target = parts[2].strip() if len(parts) > 2 and parts[2].strip() else None\n",
        "                    content = parts[3].strip() if len(parts) > 3 else \"\"\n",
        "\n",
        "                    # Validate action_type\n",
        "                    if action_type in [\"dialogue\", \"move\", \"conflict\", \"reveal\"]:\n",
        "                        actions.append(StoryAction(\n",
        "                            actor=actor,\n",
        "                            action_type=action_type,\n",
        "                            target=target if target and target != \"None\" else None,\n",
        "                            content=content\n",
        "                        ))\n",
        "\n",
        "        # If parsing fails, return hybrid fallback\n",
        "        if not actions:\n",
        "            print(\"Failed to parse LLM output, using fallback\")\n",
        "            return self._get_actions_hybrid(StoryState({}, \"village\", [], 0.5),\n",
        "                                           StoryGoal([], {}))\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def calculate_action_likelihood(self, state: StoryState, action: StoryAction) -> float:\n",
        "        \"\"\"Calculate r1: likelihood of action using LLM\"\"\"\n",
        "\n",
        "        if self.model_type == \"openai\" and OPENAI_AVAILABLE:\n",
        "            return self._calculate_likelihood_openai(state, action)\n",
        "        elif self.model_type == \"huggingface\":\n",
        "            return self._calculate_likelihood_huggingface(state, action)\n",
        "        else:\n",
        "            return self._calculate_likelihood_hybrid(state, action)\n",
        "\n",
        "    def _calculate_likelihood_openai(self, state: StoryState, action: StoryAction) -> float:\n",
        "        \"\"\"Get action likelihood from OpenAI\"\"\"\n",
        "        prompt = f\"\"\"Rate the narrative coherence of this story action on a scale of 0.0 to 1.0.\n",
        "\n",
        "Current State:\n",
        "{state.to_string()}\n",
        "\n",
        "Proposed Action:\n",
        "{action.to_string()}\n",
        "\n",
        "Consider:\n",
        "1. Character consistency (would this character do this?)\n",
        "2. Plot progression (does this advance the story?)\n",
        "3. Narrative logic (does this make sense?)\n",
        "\n",
        "Respond with ONLY a number between 0.0 and 1.0.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=10\n",
        "            )\n",
        "\n",
        "            text = response.choices[0].message.content.strip()\n",
        "            # Extract number from response\n",
        "            import re\n",
        "            match = re.search(r'[0-9]+\\.?[0-9]*', text)\n",
        "            if match:\n",
        "                score = float(match.group())\n",
        "                return min(max(score, 0.0), 1.0)  # Clamp to [0,1]\n",
        "            return 0.5  # Default\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Likelihood calculation error: {e}\")\n",
        "            return self._calculate_likelihood_hybrid(state, action)\n",
        "\n",
        "    def _calculate_likelihood_huggingface(self, state: StoryState, action: StoryAction) -> float:\n",
        "        \"\"\"Calculate likelihood using HuggingFace\"\"\"\n",
        "        prompt = f\"Rate 0-1: {action.to_string()} given {state.to_string()[:100]}\"\n",
        "\n",
        "        # Simplified scoring via HF\n",
        "        headers = {\"Authorization\": f\"Bearer {self.hf_token}\"} if self.hf_token else {}\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                self.api_url,\n",
        "                headers=headers,\n",
        "                json={\"inputs\": prompt, \"parameters\": {\"max_new_tokens\": 10}}\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                text = response.json()[0][\"generated_text\"]\n",
        "                match = re.search(r'[0-9]+\\.?[0-9]*', text)\n",
        "                if match:\n",
        "                    return min(max(float(match.group()), 0.0), 1.0)\n",
        "\n",
        "            return self._calculate_likelihood_hybrid(state, action)\n",
        "\n",
        "        except:\n",
        "            return self._calculate_likelihood_hybrid(state, action)\n",
        "\n",
        "    def _calculate_likelihood_hybrid(self, state: StoryState, action: StoryAction) -> float:\n",
        "        \"\"\"Heuristic-based likelihood calculation\"\"\"\n",
        "        score = 0.5  # Base score\n",
        "\n",
        "        # Character role consistency\n",
        "        if action.actor in state.characters:\n",
        "            char_attrs = state.characters[action.actor]\n",
        "            if \"role\" in char_attrs:\n",
        "                role = char_attrs[\"role\"]\n",
        "\n",
        "                if role == \"hero\":\n",
        "                    if \"help\" in action.content or action.action_type == \"reveal\":\n",
        "                        score += 0.2\n",
        "                elif role == \"villain\" and action.action_type == \"conflict\":\n",
        "                    score += 0.3\n",
        "                elif role == \"investigator\" and action.action_type == \"reveal\":\n",
        "                    score += 0.3\n",
        "\n",
        "        # Story tension appropriateness\n",
        "        if state.tension_level < 0.5 and action.action_type in [\"conflict\", \"reveal\"]:\n",
        "            score += 0.1\n",
        "\n",
        "        # Add some randomness for exploration\n",
        "        score += random.uniform(-0.1, 0.1)\n",
        "\n",
        "        return min(max(score, 0.0), 1.0)\n",
        "\n",
        "    def predict_next_state(self, state: StoryState, action: StoryAction) -> StoryState:\n",
        "        \"\"\"Predict next state - can use LLM or heuristics\"\"\"\n",
        "        # For efficiency, we'll use deterministic transitions\n",
        "        # You could enhance this with LLM calls for more creative outcomes\n",
        "\n",
        "        new_state = state.copy()\n",
        "\n",
        "        if action.action_type == \"dialogue\":\n",
        "            if action.actor in new_state.characters:\n",
        "                if \"relationships\" not in new_state.characters[action.actor]:\n",
        "                    new_state.characters[action.actor][\"relationships\"] = {}\n",
        "\n",
        "                if \"help\" in action.content:\n",
        "                    new_state.characters[action.actor][\"relationships\"][action.target] = \"friendly\"\n",
        "                    new_state.tension_level = max(0, new_state.tension_level - 0.1)\n",
        "                elif \"confront\" in action.content or \"secret\" in action.content:\n",
        "                    new_state.characters[action.actor][\"relationships\"][action.target] = \"tense\"\n",
        "                    new_state.tension_level = min(1.0, new_state.tension_level + 0.2)\n",
        "\n",
        "        elif action.action_type == \"move\":\n",
        "            for loc in self.locations:\n",
        "                if loc in action.content:\n",
        "                    new_state.location = loc\n",
        "                    break\n",
        "\n",
        "        elif action.action_type == \"conflict\":\n",
        "            new_state.tension_level = min(1.0, new_state.tension_level + 0.3)\n",
        "            conflict_point = f\"conflict_{action.actor}_{action.target}\"\n",
        "            if conflict_point not in new_state.plot_points:\n",
        "                new_state.plot_points.append(conflict_point)\n",
        "\n",
        "        elif action.action_type == \"reveal\":\n",
        "            revelation_num = len([p for p in new_state.plot_points if \"revelation\" in p])\n",
        "            new_state.plot_points.append(f\"revelation_{revelation_num}\")\n",
        "            new_state.tension_level = min(1.0, new_state.tension_level + 0.1)\n",
        "\n",
        "        return new_state\n"
      ],
      "metadata": {
        "id": "DcOOza_XB7ki"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAPNode:\n",
        "    \"\"\"Node in RAP-MCTS tree\"\"\"\n",
        "\n",
        "    def __init__(self, state: StoryState, parent: Optional['RAPNode'] = None,\n",
        "                 action: Optional[StoryAction] = None, depth: int = 0):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action = action\n",
        "        self.depth = depth\n",
        "        self.children: Dict[str, 'RAPNode'] = {}\n",
        "        self.visits = 0\n",
        "        self.q_value = 0.0\n",
        "        self.untried_actions: List[StoryAction] = []\n",
        "        self.is_terminal = False\n",
        "\n",
        "    def ucb1(self, c: float = 1.4) -> float:\n",
        "        if self.visits == 0:\n",
        "            return float('inf')\n",
        "        exploitation = self.q_value / self.visits\n",
        "        exploration = c * math.sqrt(math.log(self.parent.visits) / self.visits)\n",
        "        return exploitation + exploration\n",
        "\n",
        "    def best_child(self, c: float = 1.4) -> 'RAPNode':\n",
        "        return max(self.children.values(), key=lambda n: n.ucb1(c))\n",
        "\n",
        "    def add_child(self, action: StoryAction, state: StoryState) -> 'RAPNode':\n",
        "        child = RAPNode(state, parent=self, action=action, depth=self.depth + 1)\n",
        "        self.children[action.to_string()] = child\n",
        "        return child\n",
        "\n",
        "class RAP_MCTS:\n",
        "    \"\"\"RAP framework with MCTS for story planning\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 world_model: ActualLLMWorldModel,\n",
        "                 max_depth: int = 15,\n",
        "                 iterations: int = 50,\n",
        "                 exploration_constant: float = 1.4,\n",
        "                 alpha: float = 0.5):\n",
        "        self.world_model = world_model\n",
        "        self.max_depth = max_depth\n",
        "        self.iterations = iterations\n",
        "        self.c = exploration_constant\n",
        "        self.alpha = alpha\n",
        "        self.root = None\n",
        "        self.goal = None\n",
        "\n",
        "    def search(self, initial_state: StoryState, goal: StoryGoal) -> List[StoryAction]:\n",
        "        \"\"\"Main RAP-MCTS search\"\"\"\n",
        "        self.root = RAPNode(initial_state)\n",
        "        self.goal = goal\n",
        "\n",
        "        self.root.untried_actions = self.world_model.get_valid_actions(\n",
        "            initial_state, goal\n",
        "        )\n",
        "\n",
        "        for iteration in range(self.iterations):\n",
        "            node = self._selection()\n",
        "\n",
        "            if not node.is_terminal and node.untried_actions:\n",
        "                node = self._expansion(node)\n",
        "\n",
        "            reward = self._evaluation(node)\n",
        "\n",
        "            self._backpropagation(node, reward)\n",
        "\n",
        "        return self._extract_best_path()\n",
        "\n",
        "    def _selection(self) -> RAPNode:\n",
        "        current = self.root\n",
        "        while current.children and not current.is_terminal:\n",
        "            if current.untried_actions:\n",
        "                return current\n",
        "            current = current.best_child(self.c)\n",
        "        return current\n",
        "\n",
        "    def _expansion(self, node: RAPNode) -> RAPNode:\n",
        "        if not node.untried_actions:\n",
        "            return node\n",
        "\n",
        "        action = node.untried_actions.pop(0)\n",
        "        next_state = self.world_model.predict_next_state(node.state, action)\n",
        "        child = node.add_child(action, next_state)\n",
        "\n",
        "        if self._is_goal_reached(next_state) or child.depth >= self.max_depth:\n",
        "            child.is_terminal = True\n",
        "        else:\n",
        "            child.untried_actions = self.world_model.get_valid_actions(\n",
        "                next_state, self.goal\n",
        "            )\n",
        "\n",
        "        return child\n",
        "\n",
        "    def _evaluation(self, node: RAPNode) -> float:\n",
        "        \"\"\"Evaluate using dual reward system (r1 from LLM, r2 from heuristics)\"\"\"\n",
        "        if node.action:\n",
        "            r1 = self.world_model.calculate_action_likelihood(\n",
        "                node.parent.state if node.parent else node.state,\n",
        "                node.action\n",
        "            )\n",
        "        else:\n",
        "            r1 = 1.0\n",
        "\n",
        "        r2 = self._calculate_heuristic_reward(node.state)\n",
        "\n",
        "        # RAP's dual reward combination\n",
        "        reward = (r1 ** self.alpha) * (r2 ** (1 - self.alpha))\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def _calculate_heuristic_reward(self, state: StoryState) -> float:\n",
        "        \"\"\"Task-specific heuristic (r2 in RAP)\"\"\"\n",
        "        score = 0.0\n",
        "\n",
        "        # Reward for completing plot points\n",
        "        if self.goal.required_plot_points:\n",
        "            required = set(self.goal.required_plot_points)\n",
        "            completed = set(state.plot_points)\n",
        "            matching = required.intersection(completed)\n",
        "            score += len(matching) * 2.0\n",
        "\n",
        "            if required.issubset(completed):\n",
        "                score += 5.0\n",
        "\n",
        "        # Reward for correct location\n",
        "        if self.goal.target_location:\n",
        "            if state.location == self.goal.target_location:\n",
        "                score += 2.0\n",
        "\n",
        "        # Reward for relationships\n",
        "        if self.goal.target_relationships:\n",
        "            for char, target_rel in self.goal.target_relationships.items():\n",
        "                if char in state.characters:\n",
        "                    char_rels = state.characters[char].get(\"relationships\", {})\n",
        "                    for other_char, rel in char_rels.items():\n",
        "                        if rel == target_rel:\n",
        "                            score += 1.0\n",
        "                            break\n",
        "\n",
        "        # Goal completion bonus\n",
        "        if self._is_goal_reached(state):\n",
        "            score = 100.0\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _is_goal_reached(self, state: StoryState) -> bool:\n",
        "        if self.goal.required_plot_points:\n",
        "            required = set(self.goal.required_plot_points)\n",
        "            completed = set(state.plot_points)\n",
        "            if not required.issubset(completed):\n",
        "                return False\n",
        "\n",
        "        if self.goal.target_location:\n",
        "            if state.location != self.goal.target_location:\n",
        "                return False\n",
        "\n",
        "        if self.goal.target_relationships:\n",
        "            for char, target_rel in self.goal.target_relationships.items():\n",
        "                if char in state.characters:\n",
        "                    char_rels = state.characters[char].get(\"relationships\", {})\n",
        "                    has_relationship = any(\n",
        "                        rel == target_rel for rel in char_rels.values()\n",
        "                    )\n",
        "                    if not has_relationship:\n",
        "                        return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _backpropagation(self, node: RAPNode, reward: float):\n",
        "        current = node\n",
        "        while current is not None:\n",
        "            current.visits += 1\n",
        "            current.q_value += reward\n",
        "            current = current.parent\n",
        "\n",
        "    def _extract_best_path(self) -> List[StoryAction]:\n",
        "        path = []\n",
        "        current = self.root\n",
        "        visited = set()\n",
        "\n",
        "        while current.children and len(path) < self.max_depth:\n",
        "            state_key = str(current.state.plot_points) + current.state.location\n",
        "            if state_key in visited:\n",
        "                break\n",
        "            visited.add(state_key)\n",
        "\n",
        "            best_child = None\n",
        "            best_score = -float('inf')\n",
        "\n",
        "            for child in current.children.values():\n",
        "                if child.visits > 0:\n",
        "                    avg_value = child.q_value / child.visits\n",
        "                    score = avg_value + (child.visits / 10.0)\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_child = child\n",
        "\n",
        "            if best_child is None:\n",
        "                break\n",
        "\n",
        "            if best_child.action:\n",
        "                path.append(best_child.action)\n",
        "            current = best_child\n",
        "\n",
        "            if current.is_terminal or self._is_goal_reached(current.state):\n",
        "                break\n",
        "\n",
        "        return path"
      ],
      "metadata": {
        "id": "Bc_ZU1RDCJfx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_demo_scenarios():\n",
        "    \"\"\"Create demonstration story planning scenarios\"\"\"\n",
        "    scenarios = [\n",
        "        {\n",
        "            \"name\": \"Hero's Journey\",\n",
        "            \"initial_state\": StoryState(\n",
        "                characters={\n",
        "                    \"Hero\": {\"role\": \"hero\", \"status\": \"naive\"},\n",
        "                    \"Mentor\": {\"role\": \"guide\", \"status\": \"wise\"},\n",
        "                    \"Villain\": {\"role\": \"villain\", \"status\": \"hidden\"}\n",
        "                },\n",
        "                location=\"village\",\n",
        "                plot_points=[],\n",
        "                tension_level=0.1\n",
        "            ),\n",
        "            \"goal\": StoryGoal(\n",
        "                required_plot_points=[\"revelation_0\", \"conflict_Hero_Villain\"],\n",
        "                target_relationships={\"Hero\": \"friendly\", \"Mentor\": \"friendly\"},\n",
        "                target_location=\"castle\",\n",
        "                min_tension_arc=True\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Mystery Resolution\",\n",
        "            \"initial_state\": StoryState(\n",
        "                characters={\n",
        "                    \"Detective\": {\"role\": \"investigator\", \"status\": \"searching\"},\n",
        "                    \"Suspect1\": {\"role\": \"suspect\", \"status\": \"nervous\"},\n",
        "                    \"Suspect2\": {\"role\": \"suspect\", \"status\": \"calm\"}\n",
        "                },\n",
        "                location=\"home\",\n",
        "                plot_points=[],\n",
        "                tension_level=0.3\n",
        "            ),\n",
        "            \"goal\": StoryGoal(\n",
        "                required_plot_points=[\"revelation_0\", \"revelation_1\"],\n",
        "                target_relationships={\"Detective\": \"tense\"},\n",
        "                target_location=None,\n",
        "                min_tension_arc=True\n",
        "            )\n",
        "        }\n",
        "    ]\n",
        "    return scenarios\n",
        "\n",
        "def run_experiment_with_llm():\n",
        "    \"\"\"Run RAP-MCTS with actual LLM\"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"RAP-MCTS Story Planning with LLM\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize with your choice:\n",
        "    # Option 1: OpenAI (need API key)\n",
        "    # world_model = ActualLLMWorldModel(model_type=\"openai\", api_key=\"your-key-here\")\n",
        "\n",
        "    # Option 2: HuggingFace (free, may be slower)\n",
        "    # world_model = ActualLLMWorldModel(model_type=\"huggingface\", hf_token=\"your-token\")\n",
        "\n",
        "    # Option 3: Hybrid (no API needed, uses heuristics + simulated LLM)\n",
        "    world_model = ActualLLMWorldModel(model_type=\"hybrid\")\n",
        "\n",
        "    scenarios = create_demo_scenarios()\n",
        "\n",
        "    for scenario in scenarios:\n",
        "        print(f\"\\nScenario: {scenario['name']}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        rap_mcts = RAP_MCTS(\n",
        "            world_model=world_model,\n",
        "            iterations=30,  # Reduced for API cost/speed\n",
        "            alpha=0.6  # Balance between LLM and heuristics\n",
        "        )\n",
        "\n",
        "        print(\"Initial State:\")\n",
        "        print(scenario['initial_state'].to_string())\n",
        "\n",
        "        start_time = time.time()\n",
        "        best_path = rap_mcts.search(\n",
        "            scenario['initial_state'],\n",
        "            scenario['goal']\n",
        "        )\n",
        "        search_time = time.time() - start_time\n",
        "\n",
        "        print(f\"\\nGenerated Plan ({len(best_path)} steps):\")\n",
        "        for i, action in enumerate(best_path, 1):\n",
        "            print(f\"  {i}. {action.to_string()}\")\n",
        "\n",
        "        # Simulate final state\n",
        "        final_state = scenario['initial_state']\n",
        "        for action in best_path:\n",
        "            final_state = world_model.predict_next_state(final_state, action)\n",
        "\n",
        "        goal_reached = rap_mcts._is_goal_reached(final_state)\n",
        "\n",
        "        print(f\"\\nFinal State:\")\n",
        "        print(final_state.to_string())\n",
        "\n",
        "        print(f\"\\nResults:\")\n",
        "        print(f\"  Goal Reached: {'✓' if goal_reached else '✗'}\")\n",
        "        print(f\"  Search Time: {search_time:.2f}s\")\n",
        "        print(f\"  Model Type: {world_model.model_type}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # To use OpenAI, set your API key:\n",
        "    # os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n",
        "\n",
        "    # To use HuggingFace, set your token:\n",
        "    # os.environ[\"HF_TOKEN\"] = \"your-token-here\"\n",
        "\n",
        "    run_experiment_with_llm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5gpMtHZCSqy",
        "outputId": "094f4a6a-de5a-4968-f5f3-6a4ed81faa81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "RAP-MCTS Story Planning with LLM\n",
            "============================================================\n",
            "Using hybrid mode (heuristics + simulated LLM)\n",
            "\n",
            "Scenario: Hero's Journey\n",
            "----------------------------------------\n",
            "Initial State:\n",
            "Location: village\n",
            "Characters:\n",
            "  Hero: role=hero, status=naive\n",
            "  Mentor: role=guide, status=wise\n",
            "  Villain: role=villain, status=hidden\n",
            "Plot points completed: None\n",
            "Tension level: 0.1\n",
            "\n",
            "Generated Plan (2 steps):\n",
            "  1. Hero reveal: makes important discovery\n",
            "  2. Hero conflict with Villain: confronts\n",
            "\n",
            "Final State:\n",
            "Location: village\n",
            "Characters:\n",
            "  Hero: role=hero, status=naive\n",
            "  Mentor: role=guide, status=wise\n",
            "  Villain: role=villain, status=hidden\n",
            "Plot points completed: revelation_0, conflict_Hero_Villain\n",
            "Tension level: 0.5\n",
            "\n",
            "Results:\n",
            "  Goal Reached: ✗\n",
            "  Search Time: 0.00s\n",
            "  Model Type: hybrid\n",
            "\n",
            "Scenario: Mystery Resolution\n",
            "----------------------------------------\n",
            "Initial State:\n",
            "Location: home\n",
            "Characters:\n",
            "  Detective: role=investigator, status=searching\n",
            "  Suspect1: role=suspect, status=nervous\n",
            "  Suspect2: role=suspect, status=calm\n",
            "Plot points completed: None\n",
            "Tension level: 0.3\n",
            "\n",
            "Generated Plan (3 steps):\n",
            "  1. Suspect1 reveal: makes important discovery\n",
            "  2. Detective reveal: makes important discovery\n",
            "  3. Detective dialogue with Suspect2: confronts\n",
            "\n",
            "Final State:\n",
            "Location: home\n",
            "Characters:\n",
            "  Detective: role=investigator, status=searching, relationships={'Suspect2': 'tense'}\n",
            "  Suspect1: role=suspect, status=nervous\n",
            "  Suspect2: role=suspect, status=calm\n",
            "Plot points completed: revelation_0, revelation_1\n",
            "Tension level: 0.7\n",
            "\n",
            "Results:\n",
            "  Goal Reached: ✓\n",
            "  Search Time: 0.00s\n",
            "  Model Type: hybrid\n"
          ]
        }
      ]
    }
  ]
}